---
title: "Lab 6"
author: Jesse Bragger, Tori Hancheck, and Rob Golebieski
output: html_notebook
---

# GitHub Repo

https://github.com/s1075803/Lab6

# Part I

## 1

```{r}
#' This function calculates the cumulative distribution for a guassian random variable. 
#' 
#' @param x The x variable is a vector of all the values being run through the function
#' @param mean This is the mean of the distribution
#' @param var This is the variance of the distribution
#' 
#' @return cdf This w ill return the cdf of the normal distribution for a given set of numbers
pgauss<- function(x, mean = 0, var = 1){
  cdf<-rep(NA, length(x))
  for(i in 1:length(x)){
    cdf[i]<-integrate(f=function(x) dnorm(x, mean=mean, sd=sqrt(var)), lower=-Inf, upper=x[i])[[1]]
  
  }
    return(cdf)
}

```

## 2

Using the function pgauss we found that the probability of a gaussian random variable with a mean of 1 and a variance of 2 exceeding the value 3 is 0.0786. Using pnorm, we were able to get the same result.

```{r}
1 - pgauss(3, 1, 2) # Find probability

1- pnorm(3, mean=1, sd=sqrt(2)) # Check answer
```
# Part II

## 3

```{r}
curve(pnorm(x, mean = 5, sd = 10), from = -25, to = 45) # Plot CDF
abline(v=qnorm(0.25, mean = 5, sd =10)) # Add vertical line
```
The 0.25 quantile of the distribution is -2 graphically.

## 4

```{r}
#' This function will compute the quantile function for a Gaussian random variable
#' 
#' @param mean this is the mean of the distribution
#' @param var this is the variance of the distribution
#'
#' @return a.vector this will return the quantile function evaluated at all of the values in q

qgauss <- function(q, mean = 0, var=1){
  a.vector <- rep(0, length(q))
  for(i in 1:length(q)){
    a <- function(x) pgauss(x, mean, var) - q[i]
    a.vector[i] <- uniroot(a, c(mean-3*sqrt(var), mean+3*sqrt(var)))[[1]]
  }
  return(a.vector)
}
```

## 5

```{r}
qgauss(0.25, 5, 100)
qnorm(0.25, mean=5, sd=10)
```
The 0.25 quantile of a Gaussian random variable with mean \(\mu = 5\) and variance \(\sigma^2 = 100\) is -1.745. We get the same answer using qnorm(). This answer matches the graphical solution found in Problem 3.

# Part III

## 6

```{r}
#' Compute the log-likelihood function for a Gaussian random sample
#'
#' @param mean the presumed mean (mu)
#' @param var for the assumed variance (sigma^2)
#' @param data a vector containing the sample (x1,x1,...xn)
#' @return the value of the log-likelihood function for the sample

gaussian.ll <- function(mean, var, data) {
  n <- length(data)
  
  sum <- 0
  
  for (i in 1:n) {
    sum <- sum + (data[i] - mean)^2
  }
  
  log.likelihood <- (-n/2)*log(2*pi*var) - (1/(2*var))*sum
  
  return(log.likelihood)
}

gaussian.ll(mean = 0, var = 1, data = c(1, 2, 3, 4, 5)) # Check to make sure function works

log.l <- (-5/2)*log(2*pi) - (1/2)*(1 + 4 + 9 + 16 + 25)

log.l # Same answer so the function runs and gives correct output
```
## 7

```{r}
#' A vectorized version of gaussian.ll()
#'
#' @param mean a vector containing a range of mean (mu) values
#' @param var for the assumed variance (sigma^2)
#' @param data a vector containing the sample (x1,x1,...xn)
#' @return the values of the log-likelihood function for the sample

gaussian.ll.v <- function(mean, var, data) {
  n <- length(data)
  
  sum.vector <- rep(0, length(mean))
  
  for (k in 1:length(mean)) {
    
    sum <- 0
    
    mean.to.use <- mean[k]
    
  for (i in 1:n) {
    
    sum <- sum + (data[i] - mean.to.use)^2
    
  }
    sum.vector[k] <- sum
  
  }
  log.likelihood <- rep(0, length(mean))
  
  for (h in 1:length(mean)) {
    log.likelihood[h] <- (-n/2)*log(2*pi*var) - (1/(2*var))*sum.vector[h]
  }
  
  return(log.likelihood)
}

gaussian.ll.v(mean = c(0,1), var = 1, data = c(1,2,3)) # Check that function works

check1 <- (-3/2)*log(2*pi) - (1/2)*(14) # Log-likelihood for first mean

check1 # Correct output

check2 <- (-3/2)*log(2*pi) - (1/2)*(5) # Log-likelihood for second mean

check2 # Correct output
```

## 8

```{r}
set.seed(1) # Set seed so the random sample does not change each time the code runs

x <- rnorm(100, mean = 0, sd = 1) # Create vector x with a random sample of size 100 from a Gaussian distribution with mean 0 and variance 1

plot(gaussian.ll.v(mean = seq(from = -5, to = 5, by = 10/100), var = 1, data = x)) # Plot the log-likelihood function 

seq(from = -5, to = 5, by = 10/100)[52] # From the plot, approx the 52nd element of the mean range (sequence) is the maximizing value of the mean
```

The approximate value of the mean that maximizes the log-likelihood function is 0.10. This makes sense given how we generated the sample using rnorm() with a mean of 0. 0.1 is roughly 0.

# 9
By using the optimize function, The MLE for the function is 0.1088. This function can find the max or min by setting them to TRUE. 
```{r}
optimize(f=gaussian.ll.v, var=1, data=x, interval=c(-5, 5), maximum=TRUE)
mean(x)
```

# 10
The mean if x is equal to 0.1088 which is the same as number 9. The MLE for the population mean of a normal random sample is the sample mean. 
```{r}
mean(x)
```






















